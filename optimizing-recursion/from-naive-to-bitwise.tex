\documentclass[a4paper,12pt]{article}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{geometry}
\geometry{margin=1in}

\lstset{
    basicstyle=\ttfamily\footnotesize,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{orange},
    showstringspaces=false,
    breaklines=true,
    frame=single
}

\title{From Naive Recursion to Fast Exponentiation and the Binary Method}
\author{}
\date{}

\begin{document}
    \maketitle

    \section{Introduction}

    Exponentiation is a fundamental operation that appears in many computational contexts.
    A naive recursive implementation is conceptually simple but computationally expensive.
    By observing structural patterns in powers, we can progressively optimize it --- first through divide-and-conquer recursion, and later by expressing the exponent in binary form.

    \section{Naive Recursive Exponentiation}

    We want to compute \( a^n \), where \( a \) is a number and \( n \ge 0 \) is an integer.
    The simplest recursive definition follows directly from the mathematical definition:

    \[
        a^n =
        \begin{cases}
            1, & n = 0, \\
            a \cdot a^{n-1}, & n > 0.
        \end{cases}
    \]

    \begin{lstlisting}[language=Java, caption={Naive recursive exponentiation}]
double pow(double a, int n) {
    if (n == 0)
        return 1;
    return a * pow(a, n - 1);
}
    \end{lstlisting}

    This algorithm makes \( n \) recursive calls and performs \( n \) multiplications.
    Its time complexity is \( O(n) \), which becomes impractical for large exponents.

    \section{Observation: Squaring Subproblems}

    Consider the following property:
    \[
        a^n =
        \begin{cases}
        (a^{n/2})^2, & \text{if $n$ is even}, \\
        a \cdot (a^{(n-1)/2})^2, & \text{if $n$ is odd}.
        \end{cases}
    \]

    Instead of multiplying by \( a \) repeatedly, we can compute a smaller power and reuse it.
    This insight leads to a significant reduction in the number of multiplications.

    \section{Fast Recursive Exponentiation (Divide and Conquer)}

    Using the above observation, we can write a recursive function that halves the exponent at each step:

    \begin{lstlisting}[language=Java, caption={Fast recursive exponentiation}]
double fastPow(double a, int n) {
    if (n == 0)
        return 1;
    double half = fastPow(a, n / 2);
    if (n % 2 == 0)
        return half * half;
    else
        return a * half * half;
}
    \end{lstlisting}

    Each recursive call now divides the problem size by 2.
    Thus, the time complexity becomes \( O(\log n) \).

    \paragraph{Example.}
    For \( a^5 \):
    \[
        a^5 = a \cdot (a^2)^2 = a \cdot (a \cdot a)^2.
    \]
    The recursion tree has only about \( \log_2(5) \) levels.

    \section{From Recursion to Bitwise Iteration}

    The recursive idea can be expressed iteratively using binary representation of \( n \).
    Observe that:
    \[
        n = (b_k b_{k-1} \ldots b_0)_2
        \quad \Rightarrow \quad
        a^n = \prod_{i=0}^{k} (a^{2^i})^{b_i}.
    \]

    Each bit \( b_i \) determines whether the current power of \( a \) contributes to the final result.
    This leads to the well-known \emph{binary exponentiation algorithm}.

    \begin{lstlisting}[language=Java, caption={Bitwise (iterative) exponentiation}]
    double binaryPow(double a, int n) {
    double result = 1;
    double base = a;
    while (n > 0) {
    if ((n & 1) == 1)
    result *= base;
    base *= base;
    n >>= 1; // shift right (divide by 2)
    }
    return result;
    }
\end{lstlisting}

The binary version retains the \( O(\log n) \) complexity but avoids recursion,
making it more suitable for performance-critical or memory-limited systems.

\section{Summary of Evolution}

\begin{center}
    \begin{tabular}{|l|l|l|}
        \hline
        \textbf{Method} & \textbf{Idea} & \textbf{Complexity} \\
        \hline
        Naive recursion & Multiply $a$ by itself $n$ times & $O(n)$ \\
        Fast recursion & Divide $n$ by 2 each step & $O(\log n)$ \\
        Binary method & Use binary form of $n$ & $O(\log n)$ \\
        \hline
    \end{tabular}
\end{center}

\section{Conclusion}

By analyzing the structure of exponentiation and exploiting properties of powers,
we transformed a simple linear recursion into an efficient logarithmic-time algorithm.
The binary form not only optimizes the number of multiplications but also
provides a direct path to modular exponentiation, which is fundamental in cryptography.

\end{document}
